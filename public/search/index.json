[{"content":"Kubernetets社区对网络实现方案开放了CNI标准，在我们部署K8S的时候，其中有一个步骤是安装CNI包，这里就是会把CNI插件所需要的基础组建的二进制文件给安装到/opt/cni/bin，包含如下组建：\n# pwd /opt/cni/bin # ll -h -rwxr-xr-x 1 root root 2.9M Mar 26 2019 bridge -rwxr-xr-x 1 root root 7.3M Mar 26 2019 dhcp -rwxr-xr-x 1 root root 2.1M Mar 26 2019 flannel -rwxr-xr-x 1 root root 2.2M Mar 26 2019 host-device -rwxr-xr-x 1 root root 2.2M Mar 26 2019 host-local -rwxr-xr-x 1 root root 2.6M Mar 26 2019 ipvlan -rwxr-xr-x 1 root root 2.2M Mar 26 2019 loopback -rwxr-xr-x 1 root root 2.6M Mar 26 2019 macvlan -rwxr-xr-x 1 root root 2.5M Mar 26 2019 portmap -rwxr-xr-x 1 root root 2.9M Mar 26 2019 ptp -rwxr-xr-x 1 root root 1.9M Mar 26 2019 sample -rwxr-xr-x 1 root root 2.1M Mar 26 2019 tuning -rwxr-xr-x 1 root root 2.5M Mar 26 2019 vlan 上边插件类型基本会分为三种类型\n第一类，main插件，用来创建具体的网络设备的二进制文件 如： bridge（网桥设备），ipvlan，loopback（回环设备），ptp（veth pair设备），vlan\n第二类，IPAM设备，地址管理设备，负责分配IP地址的二进制文件 如：dhcp，动态分配IP，host-local预先分配的ip\n第三类，CNI社区维护的内置CNI插件 如：flannel，专门为flannel项目提供的CNI插件；tuning，通过sysctl调整网络参数的设备；portmap，通过iptables配置端口设备的文件\n上边列出了安装默认带的基本插件，像calico这种，需要先下载后，放到这个目录就可以。要实现网络解决方案，除了上边的CNI网络插件，还要有方案本身的实现。\n网络解决方案 这一部分主要是实现配置隧道设备，配置宿主机路由，配置宿主机ARP和FDB表信息等工作。如flanneld进程\n接下来就是安装flanneld本身的安装，可以使用Damonset安装，也可以使用二进制文件直接安装，安装完成后并且启动后，会在每台宿主机上生成一个配置文件，如下面所示：\n# cat /etc/cni/net.d/10-flannel.conflist { \u0026#34;name\u0026#34;: \u0026#34;cbr0\u0026#34;, \u0026#34;plugins\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;flannel\u0026#34;, \u0026#34;delegate\u0026#34;: { \u0026#34;hairpinMode\u0026#34;: true, \u0026#34;isDefaultGateway\u0026#34;: true } }, { \u0026#34;type\u0026#34;: \u0026#34;portmap\u0026#34;, \u0026#34;capabilities\u0026#34;: { \u0026#34;portMappings\u0026#34;: true } } ] } 这个文件是给容器运行时读取的，可以看到插件里面有两个，容器运行时会按照顺序加载。理论上这个目录只存在一个配置文件，如果存在多个，会按照配置文件的首字母首先加载第一个配置文件。\nCNI插件工作原理 当kubelet watch到pod被调度到本机后，就会开始进行创建pod的操作，他第一个创建的容器肯定是infra容器，这里创建容器是容器运行时，也就是dockershim组建，接着kubelet会执行setuppod方法，这个方法就是准备CNI参数，调用CNI插件准备网络。\n参数分为两部分\ndockershim的CNI环境变量\ndockershim从CNI配置文件加载到的配置信息\n变量部分最重要的CNI_COMMAND,有add方法和del分别对应添加和删除\n配置信息是dockershim需要传入CNI的部分，以json格式传输，这部分被称之为网络配置信息，传给CNI插件后，插件会修改信息，补充信息，然后调用bridge，会传入上边的两部分信息，接下来briage插件会真正的开始创建虚拟设备，分别插入网桥和容器的一端\n接下来bridge插件调用ipam插件，为设备分配ip地址，同时设置默认路由。\n接下来为cni0网桥设置ip地址，操作完成后，cni插件会把容器地址返回给dockershim，然后被kubelet添加到pod status，这些流程基本就是二层叠加类型的创建过程了。\n","date":"2020-09-17T15:00:30+08:00","permalink":"http://localhost:1313/p/k8s-cni/","title":"K8s Cni"},{"content":"Prometheus（普罗米修斯）存储经历了三个重要版本的变更v1\u0026gt;v2\u0026gt;v3，下面简述下各自版本的缺点。\nv1 2012年发布，整个数据被分为数据和原数据两部分，然后被保存在LevelDB中，并且每隔15分钟刷新一次，这样会有一个严重的问题，如果主机当机，会最长丢失15分钟的数据。v1版本有性能问题，每秒只能支持50000个样本的写入。10s周期，1000个指标，大约只能支撑500台机器的指标收集。\nv2 针对v1的问题，2015年发布了V2版本，这时候，每个时序数据用单个的文件保存，性能提高至800000样本。但是每个时序都对应一个文件，产生了严重的时序流失和写放大问题，内存使用率不断增加，经常发生OOM，同事大量文件的创建，造成了内核文件句柄过多的错误。\nv3 针对V2的问题，2017年发布了v3版本，解决了下面的问题\n当机数据丢失的问题，引入WAL 每秒1000 0000个样本接受 CPU下降3倍，磁盘IO下降10倍 普罗米修斯的本地存储也被称之为Prometheus TSDB，TSDB的设计核心包含两个，WAL和block，block有包含chunk，meta.json，index，tombstones。\n最新的block被称之为head block，支持读写，其他block只读方式存储在硬盘中。\nblock 按照时间分割成block，大小不固定，按照设定的步数生成block，如：步数3，默认两小时，则第一次两小时生成一个，6小时生成一个，18小时生成一个，生成了三次。而且block会自动合并，如将3个2小时合并成一个6小时的，减少block的个数。每个block有全局唯一的uuid，这个是包含时间戳的，可以方便的排序。\nblock内部包含如下的几部分\nchunks 压缩后的时序数据，每个大小512M index 索引，为快速查询提供的索引， tombstones，用于对数据进行软删除，如果一个block删除了部分数据，可用这个 meta.json 记录了block的原数据信息，开始时间，截止时间，样本数等 WAL 为了防止为写入磁盘的数据丢失，引入了这个机制\n相关参数 数据保存的相关参数\n\u0026ndash;storage.tsdb.retention 存储时间，默认15天 \u0026ndash;storage.tsdb.parh 存储路径 ","date":"2020-09-04T16:10:02+08:00","permalink":"http://localhost:1313/p/prometheus%E6%9C%AC%E5%9C%B0%E5%AD%98%E5%82%A8/","title":"Prometheus本地存储"},{"content":"生产环境中，我们经常需要安装指定版本的docker，稳定性和安全性方面都能得到保证。下面的教程是生产在用的一套教程，各位可以参考。\n指定版本安装docker NEW_USER=udocker adduser $NEW_USER echo \u0026#34;$NEW_USER ALL=(ALL) ALL\u0026#34; \u0026gt;\u0026gt; /etc/sudoers export docker_version=18.06.3 yum install -y yum-utils device-mapper-persistent-data lvm2 bash-completion yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo version=$(yum list docker-ce.x86_64 --showduplicates | sort -r|grep ${docker_version}|awk \u0026#39;{print $2}\u0026#39;) yum -y install --setopt=obsoletes=0 docker-ce-${version} usermod -aG docker $NEW_USER systemctl enable docker 锁定docker版本 yum install yum-plugin-versionlock yum versionlock add docker-ce docker-ce-cli yum versionlock list yum versionlock delete \u0026lt;软件包名称\u0026gt; yum versionlock clear 删除docker yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine \\ container* 修改docker参数 { \u0026#34;oom-score-adjust\u0026#34;: -1000, \u0026#34;log-driver\u0026#34;: \u0026#34;json-file\u0026#34;, \u0026#34;log-opts\u0026#34;: { \u0026#34;max-size\u0026#34;: \u0026#34;100m\u0026#34;, \u0026#34;max-file\u0026#34;: \u0026#34;3\u0026#34; }, \u0026#34;data-root\u0026#34;: \u0026#34;/home/docker\u0026#34;, \u0026#34;max-concurrent-downloads\u0026#34;: 20, \u0026#34;max-concurrent-uploads\u0026#34;: 10, \u0026#34;bip\u0026#34;: \u0026#34;169.254.30.1/28\u0026#34;, // 最好自定义一个完全不会冲突的网断 \u0026#34;insecure-registries\u0026#34;: [\u0026#34;\u0026#34;], // 公司的镜像仓库 \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;加速\u0026#34;], \u0026#34;storage-driver\u0026#34;: \u0026#34;overlay2\u0026#34;, \u0026#34;storage-opts\u0026#34;: [ \u0026#34;overlay2.override_kernel_check=true\u0026#34; ], \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;] } 对于通过systemd来管理服务的系统(比如CentOS7.X、Ubuntu16.X), Docker有两处可以配置参数: 一个是docker.service服务配置文件,一个是Docker daemon配置文件daemon.json 修改服务单元参数 /usr/lib/systemd/system/docker.service 防止docker服务OOM： OOMScoreAdjust=-1000 开启iptables转发链：ExecStartPost=/usr/sbin/iptables -P FORWARD ACCEPT 主机名配置 因为K8S的规定，主机名只支持包含 - 和 .(中横线和点)两种特殊符号，并且主机名不能出现重复 修改内核参数 net.bridge.bridge-nf-call-ip6tables=1 net.bridge.bridge-nf-call-iptables=1 net.ipv4.ip_forward=1 net.ipv4.conf.all.forwarding=1 net.ipv4.neigh.default.gc_thresh1=4096 net.ipv4.neigh.default.gc_thresh2=6144 net.ipv4.neigh.default.gc_thresh3=8192 net.ipv4.neigh.default.gc_interval=60 net.ipv4.neigh.default.gc_stale_time=120 # 参考 https://github.com/prometheus/node_exporter#disabled-by-default kernel.perf_event_paranoid=-1 #sysctls for k8s node config net.ipv4.tcp_slow_start_after_idle=0 net.core.rmem_max=16777216 fs.inotify.max_user_watches=524288 kernel.softlockup_all_cpu_backtrace=1 kernel.softlockup_panic=0 kernel.watchdog_thresh=30 fs.file-max=2097152 fs.inotify.max_user_instances=8192 fs.inotify.max_queued_events=16384 vm.max_map_count=262144 fs.may_detach_mounts=1 net.core.netdev_max_backlog=16384 net.ipv4.tcp_wmem=4096 12582912 16777216 net.core.wmem_max=16777216 net.core.somaxconn=32768 net.ipv4.ip_forward=1 net.ipv4.tcp_max_syn_backlog=8096 net.ipv4.tcp_rmem=4096 12582912 16777216 net.ipv6.conf.all.disable_ipv6=1 net.ipv6.conf.default.disable_ipv6=1 net.ipv6.conf.lo.disable_ipv6=1 kernel.yama.ptrace_scope=0 vm.swappiness=0 # 可以控制core文件的文件名中是否添加pid作为扩展。 kernel.core_uses_pid=1 # Do not accept source routing net.ipv4.conf.default.accept_source_route=0 net.ipv4.conf.all.accept_source_route=0 # Promote secondary addresses when the primary address is removed net.ipv4.conf.default.promote_secondaries=1 net.ipv4.conf.all.promote_secondaries=1 # Enable hard and soft link protection fs.protected_hardlinks=1 fs.protected_symlinks=1 # 源路由验证 # see details in https://help.aliyun.com/knowledge_detail/39428.html net.ipv4.conf.all.rp_filter=0 net.ipv4.conf.default.rp_filter=0 net.ipv4.conf.default.arp_announce = 2 net.ipv4.conf.lo.arp_announce=2 net.ipv4.conf.all.arp_announce=2 # see details in https://help.aliyun.com/knowledge_detail/41334.html net.ipv4.tcp_max_tw_buckets=5000 net.ipv4.tcp_syncookies=1 net.ipv4.tcp_fin_timeout=30 net.ipv4.tcp_synack_retries=2 kernel.sysrq=1 ","date":"2020-08-07T15:54:02+08:00","permalink":"http://localhost:1313/p/docker%E5%AE%89%E8%A3%85%E6%8C%87%E5%AE%9A%E7%89%88%E6%9C%AC/","title":"Docker安装指定版本"},{"content":"进程隔离后，本身会看不到其他的进程，此时会发生一个问题，独占资源，也就是说，我这个进程会把全部的资源全部跑满，其他的进程抢夺不到资源，这时候我们通常需要对隔离的进程进行一些资源的限制，这就是Linux 下的cgroups技术。\n简介 cgroups是control groups的缩写，是内核提供的可以限制和隔离进程组所使用的资源的机制。\n基本概念介绍\n任务，task，通常是指一个系统进程 控制组，是按照一个标准划分的一组进程，资源控制都是以控制组为单位的。一个进程可以加入到一个控制组，也可以从一个进程组迁移到另一个控制组。 层级，控制组可以组织成层级的形式，就像是一颗树。控制族群树上的子节点继承父节点的属性 子系统，一个子系统就是一个资源控制器，如cpu，mem等，代表着一种可以限制的资源。一个子系统附加到一个层级后，表示这个层级上的控制组全部受这个子系统控制。 原理 cgroups的本质是给系统进程上挂上钩子（hooks），当task运行的时候触发钩子上所附带的子系统进行检测，最终按照设置进行资源限制和优先级分配。\n/proc/cgroups可以查看支持的子系统\ncgroups提供了虚拟文件系统作为用户接口，要是用系统，必须先进行挂载，默认挂载/sys/fs/cgroups\n规则 同一个层级结构可以挂载多个子系统 ，一个子系统只能附加到一个层级结构上\n每次系统创建新层级时，该层级内的所有任务都是默认cgroups也就是root cgroups的初始成员，根层级时系统自动创建的\n一个任务可以时多个控制组的成员，但是cgroups必须是不同的层级\n父进程clone子进程时，子进程自动属于父进程所属的控制组，可以根据需要移出\n命令 lssubsys 查看全部子系统\nlscgroup 查看全部的控制组\n","date":"2020-07-24T09:55:57+08:00","permalink":"http://localhost:1313/p/cgroups/","title":"Cgroups"},{"content":"k8s集群中，可以对两种资源进行限制，一是内存，二是cpu，使用Linux cGroups进行限制\ncpu限制 在Linux系统中，CPU的限制相比较内存的限制来说，更复杂一些。但是本身都可以通过cgroups来控制的，下面是一个K8S中的资源限制示例：\nresources: requests: memory: 50Mi cpu: 50m limits: memory: 100Mi cpu: 100m 单位后缀m表示千分之一核，也就是说，在K8S中，一个cpu核心被量化为1000m。上面的示例requests需要50m，也就是百分之五的cpu，要申请一个cpu的全部核心，可以使用1000m，或者1来表示。\n这里调用docker来创建cgroups的时候，会有一些差异\nLinux系统和docker都是按照1024的时间片值来计算的，这里和K8S有24的差值。我们称之为shares\nshares用来设置CPU的相对值，如：a的shares值为1024，b的为512，则a的相对值为1024/1024+512 约为66%。shares有两个特点：\na不忙，则b可以超过他的限制，a如果忙，则不能超过66的使用值 当有一个新的c 1024shares加入时，这个值重新计算。1024/1024+1024+512=40%，所以说这个值随着cgroups数量而改变的。 上面资源限制有两个字段，一个是requests，一个是limits。requests值，对应的就是我们上文介绍的shares值来计算的。limits又是怎么计算的呢？\n其实他和requests使用的是不同的子系统来控制的。为什么会有单独的子系统呢。通过上文的介绍，你可能已经发现了，当一个进程没有设置shares的时候，他可以自由地使用cpu资源，而且shares子系统没法精准的控制使用的cpu，只能相对来控制。谷歌团队发现了这个问题，并且增加了一个子系统来控制：cpu带宽控制组。他定义了周期和配额两个属性。周期为1/10秒，100000微秒。配额为周期长度内可以使用的cpu时间数。两个配合起来可以精准的控制cpu的使用时长。周期值和配额均可以配置。\n下面是几个例子：\n# 1.限制只能使用1个CPU（每250ms能使用250ms的CPU时间） $ echo 250000 \u0026gt; cpu.cfs_quota_us /* quota = 250ms */ $ echo 250000 \u0026gt; cpu.cfs_period_us /* period = 250ms */ # 2.限制使用2个CPU（内核）（每500ms能使用1000ms的CPU时间，即使用两个内核） $ echo 1000000 \u0026gt; cpu.cfs_quota_us /* quota = 1000ms */ $ echo 500000 \u0026gt; cpu.cfs_period_us /* period = 500ms */ # 3.限制使用1个CPU的20%（每50ms能使用10ms的CPU时间，即使用一个CPU核心的20%） $ echo 10000 \u0026gt; cpu.cfs_quota_us /* quota = 10ms */ $ echo 50000 \u0026gt; cpu.cfs_period_us /* period = 50ms */ 上面例子中的100m,换算成这里就是10000/100000，默认的周期是100000，分别对应cfs_period_us=100000, cfs_quota_us=10000。\n内存限制 内存限制相对于cpu就没有那么的复杂了。他直接把你设置的值映射到cgroups的内存控制子系统上。内存限制如上文的示例，requests代表你要申请的最少内存，也就是说，节点必须有这些内存可以申请，我可以超过这个内存，也可以少于这些内存，但节点一定要有。limits代表，我使用的内存上限，一旦超过，容器就要被oom了，所以建议两个设置合理的值。\n默认限制 LimitRange 是用来设置 namespace 中 Pod 的默认的资源 request 和 limit 值，以及大小范围\napiVersion: v1 kind: LimitRange metadata: name: mem-limit-range namespace: example spec: limits: - default: # default limit memory: 512Mi cpu: 2 defaultRequest: # default request memory: 256Mi cpu: 0.5 max: # max limit memory: 800Mi cpu: 3 min: # min request memory: 100Mi cpu: 0.3 maxLimitRequestRatio: # max value for limit / request memory: 2 cpu: 2 type: Container # limit type, support: Container / Pod / PersistentVolumeClaim limitRange支持的参数如下：\ndefault 代表默认的limit defaultRequest 代表默认的request max 代表limit的最大值 min 代表request的最小值 maxLimitRequestRatio 代表 limit / request的最大值。由于节点是根据pod request 调度资源，可以做到节点超卖，maxLimitRequestRatio 代表pod最大超卖比例。 ","date":"2020-07-23T11:20:41+08:00","permalink":"http://localhost:1313/p/k8s%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6/","title":"K8S资源限制"},{"content":"动态语言在创建类的时候，是动态创建的\nclass Hello(object): def hello(self, name=\u0026#39;world\u0026#39;): print(\u0026#34;hello\u0026#34;) 上边是我们创建的一个类，我们可以使用\n\u0026gt;\u0026gt;\u0026gt; type(Hello) \u0026lt;class \u0026#39;type\u0026#39;\u0026gt; 我们使用type插件类的类型的时候，我们发现，他返回的是type类型的。\n\u0026gt;\u0026gt;\u0026gt; h=Hello() \u0026gt;\u0026gt;\u0026gt; type(h) \u0026lt;class \u0026#39;__main__.Hello\u0026#39;\u0026gt; 实例化以后，我们可以看到，h的类型是一个Hello。\n实际上，当我们使用class关键字创建类的时候，背后也是调用type函数来创建处class。\n元类是类的类，类定义类实例也就是类对象的行为，元类定义类本身的行为。一个类是一个元类的实例。\n也就是通常我们使用class关键字来定义一个类，实际上是实例化了一个元类的对象。\n梳理一下关系：先定义元类，接下来使用type或者class创建类，然后实例化创建的类，也就是成为一个对象了。可以说是非常的绕了。\n如何定义一个简单的元类：\n# 注意这里继承的是type，元类必须从type中派生 class ListMetaclass(type) def __new__(cls, name, bases, sttrs): attrs[\u0026#39;add\u0026#39;] = lambda self, vlaue: self.append(value) return type.__new__(cls, name, basesm, attrs) 如何使用自定义元类，定制创建的类？\nclass MyList(list, metaclass=ListMetaclass): pass 当我们传入关键字参数metaclass的时候，魔术就生效了，他会告诉解释器，使用ListMetaclass.new() （markdowm的问题，下划线不显示），来创建，解析下几个参数，\n1，准备创建的类的对象 2，名称， 3，类继承的父类集合， 4，类的方法集合 在一般的使用场景中，我们一般不会用到这种方式来自己构建一个元类，但是在其他的场景中，使用元类可能会更简单，如ORM。一行映射为一个对象，一个类映射为一个表。\nclass User(Model): # 定义类的属性到列的映射： id = IntegerField(\u0026#39;id\u0026#39;) name = StringField(\u0026#39;username\u0026#39;) email = StringField(\u0026#39;email\u0026#39;) password = StringField(\u0026#39;password\u0026#39;) # 创建一个实例： u = User(id=12345, name=\u0026#39;Michael\u0026#39;, email=\u0026#39;test@orm.org\u0026#39;, password=\u0026#39;my-pwd\u0026#39;) # 保存到数据库： u.save() 上面的属性类型是有框架提供，save方法是由元类提供\nclass Fied(object): def.__init__(self, name, type): self.name = name self.type = type def __str__(self): return \u0026#39;\u0026lt;%s:%s\u0026gt;\u0026#39; % (self.__class__.__name__, self.name) 基于父类定义各种的常见类型：\nclass StringFied(Field): def __init__(self, name): super(StringField, self).__init__(name, \u0026#39;varchar(100)\u0026#39;) ","date":"2020-07-11T10:19:03+08:00","permalink":"http://localhost:1313/p/%E5%85%83%E7%B1%BB/","title":"元类"},{"content":"Docker引爆了虚拟化领域对容器技术的关注，成为了现在最热门的技术之一。这边文章是对虚拟化技术的基础，名称空间进行总结。\n6大名称空间 在我的理解中，容器技术就像是一个正方体的盒子，有6个面组成，组成一个封闭的空间，这个6个面分别代表了内核系统调用的6个参数，也就是我们通常所说的6大名称空间。\n主机名和域名 UTS CLONE_NEWUTS 信号量，共享内存，消息队列 IPC CLONE_NEWIPC 进程号 PID CLONE_NEWPID 网络 NET CLONE_NEWNET 挂载点 MOUNT CLONE_NEWNS 用户 USER CLONE_NEWUSER 实际上上面的6大名称空间实在内核3.8版本以后才开始成熟的。所以最好升级内核版本，这样才稳定。\n内核系统调用 创建一个新的进程，大家都熟悉是使用系统调用clone（），也是docker使用的方法。\n他的基本用法如下：\nint clone(int (*child_func)(void *), void *child_stack, int flags, void *args) flags就是控制使用多少功能，上面6中就包含在其中\nchild_func传入子进程的主函数\nchild_stack 传入子进程的栈\nsents（）系统调用主要用于把进程加入一个已经存在的名称空间\nint sents(int fd, int nstype) fd是要加入的名称空间描述符\nnstype可以检查名称空间是否符合自己的要求，0代表不检查\nunshare()系统调用是把原进程上进行隔离，不需要启动一个新的进程\nfork()系统调用很多人比较熟悉，这里简单介绍下，fork本身去产生新进程会返回两次，一次是父进程，返回的是子进程的pid，子进程返回的是0，代表正确，负值代表错误。\n示例 uts使用 clone (child main, child_stack+STACK_SIZE, CLONE_NEWUTS| SIGCHID, NULL) ipc使用 clone (child main, child_stack+STACK_SIZE, CLONE_NEWIPC| SIGCHID, NULL) pid使用 pid名称空间属于比较重要的隔离。内核首先创建了一个根名称空间，新的名称空间都是这个空间的子节点，构成一个树状结构，这样父节点可以看到子节点的进程，并且可以影响，反之不行。\n在linux系统中，1号进程是上帝进程，一般负责管理和回收所有子进程，在名称空间中也一样，pid为1的进程对名称空间拥有特权，起特殊作用。kill命令无法影响父亲节点和兄弟节点。\n通常情况下，容器内最好运行一个进程，但是实在有多个进程的需求，1号进程就很重要，必须有管理的功能，如bash。init进程有忽略信号的权利，就是不接受信号，除非编写了逻辑。但是父亲节点的信号kill和stop信号不可忽略，父亲节点有权停止子节点。\nmount使用 历史上最早的名称空间，所以参数是CLONE_NEWNS，早起使用的是复制方法，就是把文件结构完整的复制一份给名称空间，但是存在一些问题：如无法自动挂载一些外部文件系统。\n2006年引入的挂载传播解决了这个问题，挂载传播定义了对象之间的关系，从属关系和共享关系。\n存在五种挂载状态\n共享挂载，两个名称空间互相传播时间 从属挂载，父亲空间影响儿子空间，反之不行 共享/从属挂载，同时兼具两者的特征 私有挂载，互不影响 不可绑定挂载，互不影响 默认状态下，所有的挂载对象都是私有的。\n其他名称空间基本使用基本类似。\n","date":"2020-07-05T22:30:20+08:00","permalink":"http://localhost:1313/p/namespace/","title":"Namespace"},{"content":"进程·线程·协程 概念上来说，进程和线程都是内核来进行调度的，有CPU时间片的概念，进行的是抢占式调度。协程是工作在用户空间的，是用户级线程，也就是说，协程对于内核是透明的，内核感知不到协程的存在，完全由用户程序自行控制，这样就不能像内核的进程和线程那样进行抢占式调度，只能自己协调式调度，协程主动把控制权交出去，其他协程才能执行。\n进程是资源分配和调度的基本单位，线程是CPU调度的基本单位。可以这样理解，计算机资源抽象分为计算资源和存储资源，进程可以申请存储和CPU。也就是进程可以分配运行的全部资源。线程其实是进程的一个实体，线程不能独立分配存储资源，也就是说，一个进程的多个线程是共享存储空间的。但是线程可以分配计算资源，也就是说可以参与CPU的调度。线程只拥有运行的必不可少的资源，不分配系统资源。\n一个程序至少拥有一个进程，一个进程至少拥有一个线程。\n多线程适用CPU密集型，用于多分配CPU来计算\n多线程适用于IO密集型，用于服务端响应客户端，适用于大量IO操作\n协程 本质上来说，goroutine就是协程，区别在于，Golang在runtime和系统调用多方面对goroutine进行了封装和处理，等待时间长时，会主动让出CPU。\n1，内存消耗：2K， 线程：8M\n2，线程切换，涉及16个寄存器，goroutine：涉及3个寄存器\nGO协程的实现原理 多线程编程时，上下文的切换存在一定的消耗。协程是在应用层模拟的线程，避免了上下文切换的消耗，兼顾了多线程的优点。如：一个socket连接可以用一个协程来处理。\n线程和协程的实现原理是一样的。线程切换时，需要把上一个执行的线程压栈，当前运行的线程信息出栈，协程是在应用层实现了这一点，但协程不是操作系统调度的，是应用程序调度的。但一般会问？应用程序没有cpu调度的能力啊，怎么解决呢？\n其实，协程是基于线程的。在内部实现来说，维护了一组数据结构和一组线程，真正来执行的还是线程。协程执行的代码被存储在一个队列中，待执行队列，维护的一组线程不断的拉取协程来执行。协程是怎么切换的呢？golang本身封装了系统的io函数，通过runtime统一提供给程序适用，内部调用了系统的异步io函数，当函数返回busy或者阻塞状态时，golang本身会存储状态，然后通知调度器继续执行其他协程。\nGoroutine采用的是M：N模型实现的用户态协程调度机制，也就是m个协程运行在n个系统线程上。一个goroutine执行系统调用时，系统线程会阻塞，这时候调度器会唤醒一个新的线程或者创建一个新的线程来继续执行协程。当发生管道调用时，进程可能会阻塞，但是系统线程和协程不会阻塞，会继续执行。\nGo调度模型\nM P G Sched\nM代表用户线程，M是一个大结构，里面有当前执行的协程等信息，P是处理器，用于运行协程，还有一个队列，存储了要执行的协程，G是协程\nsched是调度器，维护M和G队列等一些状态信息。\nP的数量一般取决于GoMAXPROCS环境变量，通常和核心数相等，最大限度利用CPU。\nG的数量一般会有很多，每个P都会从G的就绪队列pop操作，一般一个P负责一个队列，减少锁的开销。\n当groutine需要执行一个系统调用时，由于M是一个线程，所以必须等待完成，此时，必须保证有一个M能正常执行其他G。当系统调用返回时，M需要调度G到一个P上，继续执行，如果不能，需要把G放到全局队列中，并且自己放到线程缓存中。\nP其实是一个衔接M和G的调度上下文，负责他们直接的对接。\n调度器 上图可以清晰的看到，go程序运行时统一经过runtime来和底层交互\ngo运行时有两个队列，全局队列和本地队列，本地队列就是自己维护的队列，为了运行G，M需要持有上下文P，M从P的队列弹出G来执行。新创建的G被放在P的队列中，当M执行的P的队列为空的时候，会随机选择一个P，把他队列中的G取走一般到自己的P的队列中，也就是窃取。\n当G阻塞，M也会阻塞，runtime会把M从P上摘除，创建新的M，如果没有空闲的M的话，然后把P和M连接，继续运行。\n","date":"2020-07-01T10:05:02+08:00","permalink":"http://localhost:1313/p/goroutine/","title":"Goroutine"},{"content":"命令简介 通常在命令行执行的操作，我们称之为命令。linux中，命令分为两种类型，内部命令和外部命令。\n内部命令：随着bash加载近内存的命令 外部命令：后来安装的命令或者存储在磁盘上的命令 那外部命令是怎么被查找到的呢？其实是因为系统中存在PATH的环境变量，bash会按照PATH路径来查找命令。\n[root@ops ~]# echo $PATH /root/.pyenv/bin:/home/jdk/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/usr/local/bin/:/root/bin # 可以看到PATH变量其实存储的是以冒号分割的一个个路径，查找的过程中是按照顺序依次查找，第一个查找到的生效 如何查看一个命令的类型？可以使用type命令查看\n[root@ops ~]# type cd cd is a shell builtin [root@ops ~]# type python python is /usr/bin/python # 这里可以很清晰的看到内建命令直接显示的是内建，外部显示的是他的安装路径 内部命令查看帮助手册\n[root@ops ~]# help cd cd: cd [-L|[-P [-e]]] [dir] Change the shell working directory. Change the current directory to DIR. The default DIR is the value of the HOME shell variable. 列出全部的内建命令\n[root@ops ~]# enable enable . enable : enable alias enable cd enable hash enable help enable history enable kill ... # 这里仅展示了一部分， 但其实有部分命令是内建命令但同时也存在一个外部命令，为了防止内建被禁用时的使用。如：echo\n[root@ops ~]# type echo echo is a shell builtin # 非常清晰的看到时内建命令 [root@ops ~]# enable -n echo # 这里禁用了echo命令 [root@ops ~]# type echo echo is /usr/bin/echo # 此时echo成为了一个外部命令 通常我们要查找一个命令的详细路径，一般有两个命令\nwhich whereis 这两个命令的区别就是whereis本身会显示更详细的信息\n[root@ops ~]# which python /usr/bin/python [root@ops ~]# whereis python python: /usr/bin/python3.6m /usr/bin/python2.7 /usr/bin/python /usr/bin/python2.7-config /usr/bin/python3.6 /usr/lib/python2.6 /usr/lib/python2.7 /usr/lib/python3.6 /usr/lib64/python2.7 /usr/lib64/python3.6 /etc/python /usr/local/bin/python3.7m-config /usr/local/bin/python3.7-config /usr/local/bin/python3.7m /usr/local/bin/python3.7 /usr/include/python3.6m /usr/include/python2.7 /usr/share/man/man1/python.1.gz 这里存在一个问题，我们每次要使用一个外部命令的时候，都要查找一遍PATH吗？其实试试不需要的，当第一次找到的时候，这个命令的路径就会被存储在内存中，通常我们称之为hashed\n[root@ops ~]# hash hits command 1 /usr/bin/whereis 左侧时命中次数 ，右侧显示的是命令的绝对路径 [root@ops ~]# hash -d python # 删除python命令的hash [root@ops ~]# hash -r # 清除全部的hash 每次退出终端后hash会全部清空\n命令本身可以定义别名\n[root@ops ~]# alias h=hostname #定义一个别名h，命令为hostname [root@ops ~]# h ops [root@ops ~]# alias # 列出全部的别名 alias cp=\u0026#39;cp -i\u0026#39; alias egrep=\u0026#39;egrep --color=auto\u0026#39; alias fgrep=\u0026#39;fgrep --color=auto\u0026#39; alias grep=\u0026#39;grep --color=auto\u0026#39; alias h=\u0026#39;hostname\u0026#39; alias k=\u0026#39;kubectl\u0026#39; alias l.=\u0026#39;ls -d .* --color=auto\u0026#39; alias ll=\u0026#39;ls -l --color=auto\u0026#39; alias ls=\u0026#39;ls --color=auto\u0026#39; alias mv=\u0026#39;mv -i\u0026#39; alias rm=\u0026#39;rm -i\u0026#39; alias which=\u0026#39;alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde\u0026#39; 别名的优先级最高，大于内建命令，大于外部命令\n时间和时区 常用命令总结\n[root@ops ~]# date # 显示当前机器的时间 Sat Jun 6 13:36:27 CST 2020 [root@ops ~]# date \u0026#34;+%F\u0026#34; # 格式化当前时间 2020-06-06 [root@ops ~]# date -d \u0026#34;-10 days\u0026#34; \u0026#34;+%F\u0026#34; # 求十天前的日期 2020-05-27 硬件时间显示\n[root@ops ~]# hwclock Sat 06 Jun 2020 01:39:46 PM CST -0.037121 seconds [root@ops ~]# clock Sat 06 Jun 2020 01:39:52 PM CST -0.322863 seconds # 上边的两个命令都用来显示硬件时间 时区的相关设置\n[root@ops ~]# timedatectl list-timezones Africa/Abidjan Africa/Accra Africa/Addis_Ababa Africa/Algiers ............ # 列出全部的时区 [root@ops ~]# timedatectl set-timezone Africa/Accra # 设置时区 日历的相关显示,在Linux中使用cal命令来显示日历\n[root@ops ~]# cal # 显示现在的日期 这里今天的日志在终端是加了底色的，因为复制出来所有没有了 June 2020 Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 [root@ops ~]# cal 2020 # 显示2020年的全部月份 2020 January February March Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa 1 2 3 4 1 1 2 3 4 5 6 7 5 6 7 8 9 10 11 2 3 4 5 6 7 8 8 9 10 11 12 13 14 12 13 14 15 16 17 18 9 10 11 12 13 14 15 15 16 17 18 19 20 21 19 20 21 22 23 24 25 16 17 18 19 20 21 22 22 23 24 25 26 27 28 26 27 28 29 30 31 23 24 25 26 27 28 29 29 30 31 。。。。。。。 ","date":"2020-06-06T12:09:40+08:00","permalink":"http://localhost:1313/p/linux%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A83/","title":"Linux基础入门(3)"},{"content":"基本介绍 场景一：当我们用K8S创建了一个pod的时候，容器顶部附加了一个可写层用于程序运行时的数据读写，但在容器结束运行的时候，这个可写层也会随之消失，数据也会消失不见，数据无持久化。 场景二：每个pod都有自己的文件系统，当本次pod结束后，后创建的pod不能有效识别到前一个pod遗留的数据，数据不共享问题。 K8S通过定义存储卷来解决上述的问题。存储卷本身不是顶级资源，像pod， service那样，而是被定义为pod的一个组成部分，因为不是独立的K8S对象，不能独立的创建和删除，而且pod的所有容器均可共享使用这个卷。\n下面一个简单的应用实例，第一个容器有htdocs目录和logs目录，存放html和日志文件，第二个容器运行了一个代理来创建html，第三个容器来收集日志\n增加共享卷以后\nwebserver写入日志，日志收集器来收集日志，两个容器内的文件系统的logs文件夹应该挂载同一个卷，htdocs和html文件夹，一个生成文件，一个读取文件，也应该使用同一个共享卷。\n卷类型 K8S中有多种卷的类型，下面的列表可以参考：\nemptDir 存储临时数据的简单空目录 hostPath～ 用于将目录从work emptDir～ 存储临时数据的简单空目录 gitRepo 检出Git仓库内容来初始化 nfs 挂载pod中的NFS共享卷 谷歌高效存储卷 亚马逊弹性块存储 微软磁盘卷～ 公有云存储 cinder cephfs glusterfs～ 其他网络类型的存储 configmap secret～ K8S部分资源和集群信息公开给pod的特殊卷 PVC～ 预置或者动态配置的持久存储类型 上面有波浪线的是使用类型比较多的卷，一个容器可以挂在多个不通类型的卷到不通的目录上。\n使用示例 emptDir\napiVersion: v1 kind: Pod metadata:: name: fortune spec: containers; - images; luksa/fortune name: html-gen volumeMounts: - name: html # 挂载的卷的名称 mountPath: /var/htdocs # 这里指明容器内的挂在位置 ....... volumes: - name: html # 这里定义了一个卷 emptyDir: {} hostPath\n这种类型属于比较常用的，我们生产线上都是挂载hostpath进去，写日志，ds filebeat去收集本机的日志到某一个日志机上\nvolumeMounts: - mountPath: /home/logs # 挂载位置 name: hostpath # 卷名称 .... volumes: - name: hostpath #卷名称 hostPath: path: /www-volume/logs # 主机路径 PV\u0026amp;\u0026amp;PVC 之前的两种类型都需要pod的开发人员了解集群中的真实网络存储的基础设施，这对专业开发人员并不友好，理想的状况是，开发人员不需要知道这些底层设施，当我需要时，申请就可以了。 这就是pv和pvc的作用。\n# 定义持久卷 apiVersion: v1 kind: persistentVolume metadata: name: mongodb-pv spec: capacity: storage: 1Gi # 大小 accessModes: # 可以被单个客户端挂载 - ReadWriteOnce - ReadOnlyMany persistentVolumeReclimPolicy: Retain # 声明被释放后，pv将会保留 gcePersistentDisk: pdName: mongodb fstype: ext4 持久卷不属于任何名称空间，是集群层面的资源，持久卷声明是属于某一个名称空间的资源，不能跨名称空间调用\n# pvc apiVersion: v1 kind: pVC #这里应该写全称 metadata: name: monfodb-pvc spec: resource: requests: storage: 1Gi accessModes: - ReadWriteOnce storageClassName: \u0026#34;\u0026#34; ... volumes: - name: mongodb-data persistentVolumeClaim: claimName: monfodb-pvc 删除持久卷：remian模式下需要手动释放\n回收策略配置： recycle 和 delete将会自动释放持久卷\nstorageclass 使用pv和pvc可以屏蔽底层的基础设施，但是仍但需要一个集群管理员来创建pv，为了解决这个问题，可以通过动态配置持久卷来自动自行次任务。\n创建storageclass需要一个中间程序来连接我们的存储，无论是网络存储，云存储还是其他的存储。\napiVersions: storage.k8s.io/v1 kind: StorageClass metadata: name: fast procisioner: kubenet. #这里是插件 parameters: type: pd # 传给插件的参数 。。。 pvc声明 spec: storageClass:fast ... ","date":"2020-05-16T11:20:29+08:00","permalink":"http://localhost:1313/p/k8s-vloume/","title":"K8S-Vloume"},{"content":" 内核参数 值 解释 /proc/sys/net/ipv4/tcp_max_syn_backlog 2048 调整半连接队列的大小 /proc/sys/net/core/somaxconn 2048 tcp最大连接数 连接取决于这两个值的最小值 net.ipv4.ip_forward 1 打开转发 /proc/sys/net/ipv4/tcp_tw_recycle 0 time wait快速回收，千万不要打开，1是打开，会出现connect timeout的问题 对客户端和服务器同时起作用，开启后在 3.5*RTO 内回收，负载会把 timestamp 都给清空 /proc/sys/net/ipv4/tcp_tw_reuse 0 复用timewaite连接，打开的意义不大，因为这个状态出现在客户端 nginx参数 值 解释 worker_processes 8 工作进程数量,和cpu数量相等就行 use epoll; 使用epoll worker_connections 10240 单个工作进程允许建立的最多连接数 server_names_hash_bucket_size 512 server name 的hash表大小 server_names_hash_max_size 1024 最大的大小 underscores_in_headers on 开启使用自定义http头部的选项，支持特定的业务 sendfile on 使用sendfile 好处：两个描述符之间直接传输数据，完全在内核操作，不需要先 read 再 write，没有上下文切换开销 tcp_nopush on 启用了sendfile才生效，启用后数据包增加到一定大小才会发送，提升网络效率 tcp_nodelay on 禁用 Nagle 算法， 加快发送数据，keepalived连接才会启用 / / 上面两个的参数同时开启，最终的效果是先填满包，再尽快发送。 keepalive_timeout 600s 长链接超时时间 keepalive_requests 409600 一个长链接可以处理的客户端的请求数量最大值 client_header_buffer_size 512k 请求头缓存大小，若请求头大，应该设置，减少内存分配的次数 client_max_body_size 2000M 请求头body的大小，默认1M。不设置上传文件会发生413 client_body_buffer_size 100M body缓冲区大小，若超过写入文件 large_client_header_buffers 4 1024k 当超过 上面的buffersize 使用这个，最大使用四个大小 proxy_buffer_size 8192k 代理缓存的大小，nginx-后端服务的缓存大小 proxy_buffers 32 8192k 到后端服务的缓存超过后最多可以申请多少缓存块 proxy_headers_hash_bucket_size 6400 代理的后端服务的hash表大小，一次分配的大小 proxy_headers_hash_max_size 51200 代理的后端服务hash表最大可以多少 proxy_connect_timeout proxy_read_timeout proxy_send_timeout 60 这三个值和后端服务同时的超时时长，设置成一样就可以 ","date":"2020-04-26T18:19:27+08:00","permalink":"http://localhost:1313/p/nginx-%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98/","title":"Nginx 参数调优"},{"content":"ReplicationController 一种k8s的资源类型，可以确保pod始终处于运行状态，如果减少则重新创建，增加则删除pod\nRC主要有三个部分\nlabel Selector： 标签选择器\nReplica count：副本个数\npod template： pod 模板\n这里需要注意的是标签选择器所选择的标签和pod模板内的标签必须是一致的，这样pod才会受RC控制。\nReplicaSet RC资源的进阶版，主要增强了RC的标签选择器功能，RC的标签选择器只支持等式选择，如：env=dev或者app=nginx。RS增强了这部分功能，支持env in dev or pro 这种写法，就是表达式写法，可以让我们有更灵活的使用。\nDeployment 一种资源类型，在生产环境中，通常使用更高级的资源来创建pod，不直接使用RC和RS，通常也不直接创建pod，而是使用副本控制器来创建pod，因为他能使pod维持在我们期望的一个状态，一旦有pod死掉，也会重新复制出来新的副本来维持我们所需要的状态。但是如果不使用副本控制器来创建，当前pod死掉，就真的死掉了，会直接影响业务。deployment是RS的高级封装，使用更友好。\n[root@kong-ali-bj-001 ~]# kubectl run nginx --image=cargo.caicloud.io/caicloud/nginx:1.9.7 --replicas=1 kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead. deployment.apps/nginx created 上边提示的是建议使用，可以看到一个deployment被创建了 如何获取我们刚才创建的deployment\n[root@kong-ali-bj-001 ~]# kubectl get deployment NAME READY UP-TO-DATE AVAILABLE AGE nginx 1/1 1 1 22s 可以获得刚才创建好的 Label 标签在kubernetes是非常重要的概念，基本上各类控制器都要依赖标签来选择对应的资源，例如：deployment根据pod的标签来选择相对应的pod，污点也是根据标签来选择容忍的。\n查看node的标签\n[root@kong-ali-bj-001 ~]# kubectl get node --show-labels NAME STATUS ROLES AGE VERSION LABELS kong-ali-bj-001 Ready master 28d v1.17.3 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=kong-ali-bj-001,kubernetes.io/os=linux,node-role.kubernetes.io/master= pgsql-ali-bj-001 Ready \u0026lt;none\u0026gt; 28d v1.17.3 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=pgsql-ali-bj-001,kubernetes.io/os=linux 可以看到 beta.kubernetes.io/arch=amd64 这种类型的就是标签 查看pod的标签\n[root@kong-ali-bj-001 ~]# kubectl get pod --show-labels NAME READY STATUS RESTARTS AGE LABELS myrepo-nwwn7 1/1 Running 0 28d run=myrepo,test_label=pro myrepo-qdhng 1/1 Running 0 28d run=myrepo nginx-6645f84fcd-q9294 1/1 Running 0 8m55s pod-template-hash=6645f84fcd,run=nginx 对pod添加标签\n[root@kong-ali-bj-001 ~]# kubectl label pod myrepo-nwwn7 tt=aa pod/myrepo-nwwn7 labeled label添加成功 kubectl get pod --show-labels NAME READY STATUS RESTARTS AGE LABELS myrepo-nwwn7 1/1 Running 0 28d run=myrepo,test_label=pro,tt=aa 可以看到添加上去的lable configmap k8s用来管理配置资源信息的一种资源类型。通过单独创建configmap，再将configmap挂载到pod内部，分离配置和应用。创建configmap可以从yaml文件和文件中创建，普通文件的格式类似如下：\nclor.good=true map.ip=10.10.10.10 可以看到也是key-vlaue类型的\n[root@kong-ali-bj-001 ~]# kubectl create configmap test --from-file=test.pro configmap/test created 从文件创建configmap [root@kong-ali-bj-001 ~]# kubectl get configmap NAME DATA AGE test 1 40s 获取configmap [root@kong-ali-bj-001 ~]# kubectl describe configmap test Name: test Namespace: default Labels: \u0026lt;none\u0026gt; Annotations: \u0026lt;none\u0026gt; Data ==== test.pro: ---- color.good=true allow=true Events: \u0026lt;none\u0026gt; 查看configmap的详细信息 ","date":"2020-03-28T23:21:09+08:00","permalink":"http://localhost:1313/p/kubernetes%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B52/","title":"Kubernetes基本概念(2)"},{"content":"概述 熟悉windows系统的同学都知道，win系统本身是存在分区盘符的概念的，如：C盘一般是存放我们的系统文件。其实任何操作系统都是有文件系统的，这样才可以存放我们的文件，linux也不例外。但是Linux和windows组织的方式是不太一样的，在linux中第一个分区称之为根分区，采用符号“/”来表示，下面一张图可以看到基本的分区结构，这里的分区结构展示的MBR类型的分区,GPT另作讨论：\n在mbr类型的分区中，主分区+扩展分区=4个分区，而且扩展分区最多有一个，不直接存储数据，而是划分为逻辑分区后再存储数据，这里的分区主要是针对单个磁盘说的。MBR类型的分区最大支持的磁盘大小为2T，至于为什么，后面会详细讲述。其实生产环境中用到扩展分区真的很少，大多数都是一个硬盘上就存在一个分区。逻辑分区的号码一般是从5开始的。\nlsblk命令： 查看全部磁盘和磁盘的分区 [root@ops ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT vdb 253:16 0 500G 0 disk └─vdb1 253:17 0 500G 0 part vda 253:0 0 100G 0 disk └─vda1 253:1 0 100G 0 part / 上篇文章有解析 Linux用户 Linux的账户类型分为两类：1，管理账户。2，普通用户\n管理账户用于管理操作系统，普通用户一般权限有限，只能做一些仅有的操作，像查看日志这些基本的功能\n其中root账户比较特别，是超级管理员，拥有全部的权限，危险性很高，轻易不要暴露\n系统账号的ID，在centos6系统中，普通账户的ID从500开始，500之前是管理账户，centos7普通用户从1000开始，之前是管理账户，而root一般是0号账户\n[root@ops ~]# echo $UID 0 用于查看当前登陆账户的ID 终端 终端是指我们当前操作的页面，这个页面可以是命令行，也可以是桌面。终端分为两种：1，物理终端，2，虚拟终端\n物理终端：一般是说/dev/consol，也就是通常所说的连接机器的显示器和键盘\n虚拟终端：一般指远程连接过来的终端,/de/pts/0\n模拟终端：指和我们交互的命令行窗口，一般通过ctrl+alt+F(1~6)切换模拟终端 /dev/tty\n[root@ops ~]# tty /dev/pts/0 查看所有的终端 运行级别 在linux中存在运行级别的概念\n0级别：关机\n1级别：单用户模式\n3级别：命令行模式\n5级别：桌面模式\n6级别：重启\n[root@ops ~]# init (0 1 3 5 6) 根据上述的解释分别的操作 shell linux中和人命令行交互的程序叫shell，也就是壳，他是命令解释器+高级语言，也就是说，shell是一种变成语言，也是一种交互方式。shell介于系统调用外部，和库函数同级别\nshell既然是一种交互的方式，那就存在很多种实现，现在基本上最流行的是bash，在mac上比较流行zsh\n[root@ops ~]# echo $SHELL /bin/bash 查看当前使用的shell类型 [root@ops ~]# cat /etc/shells /bin/sh /bin/bash /usr/bin/sh /usr/bin/bash 查看当前系统支持的shell类型 其实有一种特别的shell/sbin/nologin可以看到是不可登陆shell，这种shell主要用于应用程序的运行，不需要交互的登陆终端，更安全。\n[root@ops ~]# getent passwd root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin sync:x:5:0:sync:/sbin:/bin/sync shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown halt:x:7:0:halt:/sbin:/sbin/halt mail:x:8:12:mail:/var/spool/mail:/sbin/nologin 。。。。。 获取全部的用户信息 [root@ops ~]# getent passwd root root:x:0:0:root:/root:/bin/bash 获取单个用户的详细信息 who:显示用户 [root@ops ~]# who root pts/0 2020-03-27 23:01 (10.10.20.40) 用户 虚拟终端号 登陆时间 IP地址 [root@ops ~]# who -b system boot 2019-08-13 14:28 显示系统启动时间 whom: 显示用户 [root@ops ~]# whoami root iconv:win系统文件转换linux格式，不常用 iconv -f gb2312 file1 -o file2 其他的杂项 想要修改登录后的提示信息可以修改/etc/motd文件\n","date":"2020-03-27T22:29:06+08:00","permalink":"http://localhost:1313/p/linux%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A82/","title":"Linux基础入门(2)"},{"content":"概述 冯诺伊曼体系结构的计算机是现在计算机系统的基石。现代计算机系统，在整体上划分为硬件系统和软件系统。硬件系统又包括内部的硬件和外部的硬件。内部硬件主要包含CPU和内存，cpu就包含传统的控制器和运算器还有寄存器这些，内存分为RAM（随机存取存储器），ROM（只读存储器）。外部设备又包含硬盘存储，输入和输出设备等。而软件主要分为系统软件和应用软件。系统软件有操作系统，数据库系统这些。应用软件主要是通用软件和专用软件，如360杀毒是应用软件，如erp系统就属于专用软件。\n操作系统是基石，也是最重要的系统软件，是和硬件交互的主要渠道，也是各类应用软件的载体。Linux操作系统是主流的操作系统，是开源领域软件的杰出代表，占据服务器的操作系统的大部分市场，可以说Linux系统是非常重要的。\n通常所说的linux系统，主要指带Linux内核，根据开源软件协议，各发行商将工具融合和linux一起打包成便于操作的系统，这就是不同的linux发型版的由来。linux的发型版是非常多的，而主流的主要分为如下的几个：\n系统名称 代表1 代表2 Fedora系 redhat centos debian系 ubuntu 发型版系统= linux内核+GNU工具\n计算机体系结构方面的知识可以参照上图，具体和详细的可以推荐参考《计算机组成原理》这本书，作者是唐朔飞，这是很多大学计算机专业课用书，专业度毋庸置疑。链接在这里组成原理链接\n命令总结 lscpu命令：查看当前机器的cpu信息 [root@ops ~]# lscpu Architecture: x86_64 CPU op-mode(s): 32-bit, 64-bit Byte Order: Little Endian CPU(s): 4 On-line CPU(s) list: 0-3 Thread(s) per core: 2 Core(s) per socket: 2 Socket(s): 1 NUMA node(s): 1 Vendor ID: GenuineIntel CPU family: 6 Model: 85 Model name: Intel(R) Xeon(R) Gold 6151 CPU @ 3.00GHz Stepping: 4 CPU MHz: 3000.000 BogoMIPS: 6000.00 Hypervisor vendor: KVM Virtualization type: full L1d cache: 32K L1i cache: 32K L2 cache: 1024K L3 cache: 25344K NUMA node0 CPU(s): 0-3 file命令：查看文件类型 [root@ops ~]# file alertmanager alertmanager: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, not stripped 可执行文件 [root@ops ~]# file a.json a.json: ASCII text 文本文件 [root@ops ~]# file control.sh control.sh: Bourne-Again shell script, ASCII text executable shell文件 hexdump命令：查看二进制文件的内容 [root@ops bin]# hexdump -c -n 100 redis-cli 0000000 177 E L F 002 001 001 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 \\0 0000010 002 \\0 \u0026gt; \\0 001 \\0 \\0 \\0 4 e @ \\0 \\0 \\0 \\0 \\0 0000020 @ \\0 \\0 \\0 \\0 \\0 \\0 \\0 ` 345 \\a \\0 \\0 \\0 \\0 \\0 0000030 \\0 \\0 \\0 \\0 @ \\0 8 \\0 \\t \\0 @ \\0 \u0026amp; \\0 % \\0 0000040 006 \\0 \\0 \\0 005 \\0 \\0 \\0 @ \\0 \\0 \\0 \\0 \\0 \\0 \\0 0000050 @ \\0 @ \\0 \\0 \\0 \\0 \\0 @ \\0 @ \\0 \\0 \\0 \\0 \\0 0000060 370 001 \\0 \\0 0000064 -c: 16进制格式查看 -n 100: 显示前100位 lsblk: 查看所有的块设备 [root@ops bin]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT vdb 253:16 0 500G 0 disk └─vdb1 253:17 0 500G 0 part vda 253:0 0 100G 0 disk └─vda1 253:1 0 100G 0 part / 名字 主设备号:次设备号 移动设备 大小 只读 类型 挂载点 移动设备 标记为1 只读设备 标记为1 注意观察size的大小，size小于1K的基本是扩展分区，关于分区，后续会讲到\nsha1sum：查看哈希校验码 [root@ops bin]# sha1sum redis-cli f03302d1760eba294b8996e59b9b56f519499869 redis-cli ldd：查看命令使用的链接库 [root@ops bin]# ldd redis-cli linux-vdso.so.1 =\u0026gt; (0x00007ffd40ba2000) libm.so.6 =\u0026gt; /lib64/libm.so.6 (0x00007f68af811000) libdl.so.2 =\u0026gt; /lib64/libdl.so.2 (0x00007f68af60d000) libpthread.so.0 =\u0026gt; /lib64/libpthread.so.0 (0x00007f68af3f1000) libc.so.6 =\u0026gt; /lib64/libc.so.6 (0x00007f68af024000) /lib64/ld-linux-x86-64.so.2 (0x00007f68afb13000) dd: 转换和复制一个文件 [root@ops ~]# dd if=/dev/zero of=f1 bs=1M count=100 100+0 records in 100+0 records out 104857600 bytes (105 MB) copied, 0.0613801 s, 1.7 GB/s if: 文件源 of: 目的文件 bs: 单个块大小 count: 总共写入多少块 总大小=bs乘count 其他相关总结 cpu指令集：x86架构主要使用CISC复杂指令集，价格相对便宜，还有 RISC精简指令集和EPIC并行指令代码，主要用于专用的服务器，价格相对高昂\nbit和byte：位和字节，b和B，1B=8b，也就是一字节等于8位\nLinux哲学思想 一切都是一个文件\n小型，单一用途的程序\n链接程序，共同完成复杂的操作\n避免令人困惑的用户界面\n配置数据存储在文本中\n","date":"2020-03-16T23:33:11+08:00","permalink":"http://localhost:1313/p/linux%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A81/","title":"Linux基础入门(1)"},{"content":"TCP连接总结 最近一些时间线上的服务器会报TcpListenDrop和TcpOverFlowed的警告，一开始是不知道这究竟什么含义,然后开始研究tcp队列的相关含义，下面进行一些总结。 TCP三次握手，四次分手是大家耳熟能详的过程，甚至多数人都能说明“为什么三次握手和四次握手”，但是当我们真正去实际的解决问题的时候，我们往往不能将这些理论和实际结合起来，我相信大多数的技术人员甚至不能说明整个连接过程的11种状态，这也就是为什么我们不能实际的解决问题，因为状态的变化，可以为我们提供非常多的有效信息，下面一张图搞定这些状态的变化和出现的终端。 这张图很清晰展现了tcp从建立连接到数据传输完成断开连接的整个状态的变化，这里对每个状态简要的进行说明下：\n服务端 这里一般是指被动接受的一方，不一定非得是服务器的一端； LISTEN:这个状态是服务端最开始状态，此时等待客户端进行连接； SYN_RCVD:这个状态是等待客户端进行确认的状态，此时客户端发来确认位，即可建立连接； ESTABLISHED: 著名的连接建立状态； CLOSE_WAIT:客户端主动发起分手，服务端收到请求，并且确认后的状态； LAST_ACK:服务端发起最后一次分手后的状态，此时等待客户端确认; CLOSE:关闭状态，客户端回复最后一次分手后的状态；\n客户端 这里一般是指主动发起连接的一方，不一定是终端用户； CLOSED:被动关闭状态，此时可以调connect方法连接服务端； SYN_SEND:发送完连接后的状态,此时等待服务端回复； FIN_WAIT1:主动调用close方法后的状态，此时发送了一个fin信号； FIN_WAIT2: 收到服务端对第一次发起fin状态的回复后的状态，此时等待服务端调用close方法，发起最后一次fin； TIME_WAIT:此时服务端主动发送了最后一次FIN,客户端接收后，恢复了确认位，进入这个状态，等待最后的超市关闭,下面一段记录了几个内核参数，用于调整TCP的一些状态；\nnet.ipv4.tcp_syncookies = 1 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭； net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭； net.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。 net.ipv4.tcp_fin_timeout 修改系默认的 TIMEOUT 时间 ","date":"2020-03-06T23:03:27+08:00","permalink":"http://localhost:1313/p/tcp%E9%97%AE%E9%A2%98/","title":"TCP问题"},{"content":"容器启动之前，镜像必须先存在本地，如果本地不存在镜像，回去仓库获取镜像，并且pull的本地\n获取镜像 获取镜像的命令是docker pull命令，命令格式如下：\ndocker pull [选项] [docker registry 地址/仓库名:标签] 具体的参数选项可以通过docker pull --help查看到。一般情况下获取镜像的命令是docker pull 用户名/仓库名：tag，如果没写用户名，则代表是官方的镜像库，如：docker pull centos:7.4,就是获取centos的7.4版本的镜像。上面的命令没有给出地址，所以默认从docker hub获取。如果不写版本，则拉取标签为latest的镜像。\n运行容器 本地存在镜像以后，我们便可以尝试去运行镜像了，运行容器使用docker run命令，格式如下:\n$ docker run -it --rm \\ ubuntu:18.04 \\ bash -it 以交互式方式运行 --rm 退出停止删除 bash 容器启动后运行的命令 可以看到一个和正常的系统一样的终端，就是我们运行起来的容器了。\n列出镜像 一台安装有docker的机器上，使用docker image ls命令可查看全部已存在镜像，如下所示：\n$ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE redis latest 5f515359c7f8 5 days ago 183 MB nginx latest 05a60462f8ba 5 days ago 181 MB mongo 3.2 fe9198c04d62 5 days ago 342 MB \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 00285df0df87 5 days ago 342 MB ubuntu 18.04 f753707788c5 4 weeks ago 127 MB ubuntu latest f753707788c5 4 weeks ago 127 MB 包含仓库名 标签 镜像id 创建时间 大小，请注意这里看到的镜像体积不一定是是实际的大小，因为镜像本身和分层构建的，可能这个镜像的前面几层适合别人复用的层。另外这里的镜像大小要比docker hub上大，这是因为docker hub上包含的镜像大小是压缩后的大小。 docker image ls ubuntu可以列出所有仓库名称为ubuntu的镜像，上述的镜像列表中可以看到一个《none》的镜像，这种镜像叫做虚悬镜像，产生这种镜像的原因一般是有新的镜像和这个镜像重复名称和tag导致原本的镜像名称和tag被占用，从而名称变成none，下面的命令可以专门的查看这类镜像docker image ls -f dangling=true\n$ docker image ls -f dangling=true REPOSITORY TAG IMAGE ID CREATED SIZE \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 00285df0df87 5 days ago 342 MB 一般来说这类镜像已经失去了价值，除了占空间已经无用，可以删除掉，使用docker image prune删除。\n删除镜像 删除镜像使用docker image rm命令，一般删除的时候使用镜像ID来删除，docker image ls列出的IMAGE ID是这个镜像的短ID，docker image ls --digests列出的是镜像的长ID，删除镜像会产生两种类型的信息 untagged和deleted一种是标记取消，一种是镜像层删除，当镜像层不被其他的镜像标记或者依赖的时候，就会在执行删除操作的时候被删除，下面是一些演示：\n$ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE centos latest 0584b3d2cf6d 3 weeks ago 196.5 MB redis alpine 501ad78535f0 3 weeks ago 21.03 MB docker latest cf693ec9b5c7 3 weeks ago 105.1 MB nginx latest e43d811ce2f4 5 weeks ago 181.5 MB 镜像列表 $ docker image ls --digests REPOSITORY TAG DIGEST IMAGE ID CREATED SIZE node slim sha256:b4f0e0bdeb578043c1ea6862f0d40cc4afe32a4a582f3be235a3b164422be228 6e0c4c8e3913 3 weeks ago 214 MB $ docker image rm node@sha256:b4f0e0bdeb578043c1ea6862f0d40cc4afe32a4a582f3be235a3b164422be228 Untagged: node@sha256:b4f0e0bdeb578043c1ea6862f0d40cc4afe32a4a582f3be235a3b164422be228 长格式删除 $ docker image rm 501ad78535f0 Untagged: redis:alpine Untagged: redis@sha256:f1ed3708f538b537eb9c2a7dd50dc90a706f7debd7e1196c9264edeea521a86d Deleted: sha256:501ad78535f015d88872e13fa87a828425117e3d28075d0c117932b05bf189b7 Deleted: sha256:96167737e29ca8e9d74982ef2a0dda76ed7b430da55e321c071f0dbff8c2899b Deleted: sha256:32770d1dcf835f192cafd6b9263b7b597a1778a403a109e2cc2ee866f74adf23 Deleted: sha256:127227698ad74a5846ff5153475e03439d96d4b1c7f2a449c7a826ef74a2d2fa Deleted: sha256:1333ecc582459bac54e1437335c0816bc17634e131ea0cc48daa27d32c75eab3 Deleted: sha256:4fc455b921edf9c4aea207c51ab39b10b06540c8b4825ba57b3feed1668fa7c7 短格式删除 $ docker image rm centos Untagged: centos:latest Untagged: centos@sha256:b2f9d1c0ff5f87a4743104d099a3d561002ac500db1b9bfa02a783a46e0d366c Deleted: sha256:0584b3d2cf6d235ee310cf14b54667d889887b838d3f3d3033acd70fc3c48b8a Deleted: sha256:97ca462ad9eeae25941546209454496e1d66749d53dfa2ee32bf1faabd239d38 仓库名和标签删除 镜像的基本操作就介绍到这里了，更详细的用法，请参考官方文档。\n","date":"2020-03-05T23:03:27+08:00","permalink":"http://localhost:1313/p/docker%E9%95%9C%E5%83%8F%E6%93%8D%E4%BD%9C/","title":"Docker镜像操作"},{"content":"概述 对于整个docker容器技术的体系来说，主要划分为三部分：镜像，容器和仓库\n什么是镜像 在操作系统的体系，整个空间被横向切割为两大空间，内核空间和用户空间，在Linux系统启动的时候，内核启动后，会挂载一个root文件系统为用户空间提供支持，而镜像其实就是一个root文件系统，但是是一种特殊的root文件系统，提供包含了容器运行时所需要的程序，文件，资源，库，配置，还包含一些环境变量，用户等，镜像包含的全是静态的文件，在构建完成后，将不会改变。\n如何形象的理解镜像？其实我们可以想象一下，镜像其实就是一个高层楼房，是有一层层叠加构成的。最初，什么也没有的时候就是空白镜像。后来我在空地上建了一层房子，并且分割好一个个房间，把东西分门别类的放进去，这就构成了我们的镜像，这里镜像可能是流行的发型版，如：红帽，乌班图等。后来，我发现我需要一个新的功能，但是一层已经建好，而且摆放好了，我只能再建一层，把我要的东西存储进去。所以整体看起来，镜像是分层的。这里就会存在一个问题，二层可能有三个住户，他们都想去一层修改东西，这就会导致大家读到的东西是不一致的，为了解决这个问题，一层就规定，我这一层是只能读的，不能写，你们要写，请复制一份到你们那里，自己修改。\n镜像使用的技术 Union FS 联合文件系统是镜像技术使用的文件系统技术，为什么使用这个技术？镜像包含一个root文件系统，一般来说可能会比较大，所以使用分层存储的架构，ISO类型的镜像和这个是不一样的，这里的docker镜像其实是一个虚拟的概念，其最终的体现往往是一组文件系统的组合，而ISO一般是一个打包好的文件。 镜像build时一般是一层层生成，前一层是后一层的基础，本层build完就会固定，不会发生改变了，执行删除操作一般是标记为不可见，文件会一直存在，因此构建是尽量减少冗余文件的生成。\n什么是容器 镜像和容器的关系，就像程序和进程的关系，容器就是运行时的镜像，容器可以被启动，停止，删除，暂停等，镜像一般只能被创建和删除。容器运行时会被添加一层可写层在最上边，用于容器运行时的数据增删改查，停止后会消失，不被保存，如何保存，会在后续的文章中说明。 容器运行的本质是进程,但和普通的进程是不一样的，他被添加了障眼法，运行在一个与世隔绝的空间内，也就是自己的名称空间内，就好像是一个独立的用户空间一样。空间内有自己的网络配置，用户，进程等。\n什么是仓库 仓库，顾名思义就是存储镜像的地方，因为我们的镜像不是运行在一个主机上，在多个主机之间进行镜像的传输，就需要有一个存储和分发镜像的地方，就是仓库。一个仓库通常被永爱存储同一个镜像的不同版本，仓库被residtry统一管理。仓库名通常xx/xx:tag这种格式，用户名/服务名:tag,一般在私有仓库中往往是 地址or域名:端口/服务名:tag,这种格式，公有的docker registry是docker hub，私有的包含harbor或者nexus，或者官方的regisitry api。\nDocker Hub 官方仓库地址\ndocker结构分解 containerd is a container runtime which can manage a complete container lifecycle - from image transfer/storage to container execution, supervision and networking. container-shim handle headless containers, meaning once runc initializes the containers, it exits handing the containers over to the container-shim which acts as some middleman. runc is lightweight universal run time container, which abides by the OCI specification. runc is used by containerd for spawning and running containers according to OCI spec. It is also the repackaging of libcontainer. grpc used for communication between containerd and docker-engine. OCI maintains the OCI specification for runtime and images. The current docker versions support OCI image and runtime specs. ","date":"2020-03-04T23:03:27+08:00","permalink":"http://localhost:1313/p/docker%E4%B8%89%E9%83%A8%E6%9B%B2/","title":"Docker三部曲"},{"content":"node node即节点，是物理服务器或者虚拟服务器，他们是组成kubernetes资源池的基础。节点分为两种色，master节点和worker节点。master节点负责资源调度，集群状态控制等，worker节点负责运行用户容器，承接负载。\n获取node信息 通过kubectl命令可以获取node信息\n$ kubectl get nodes NAME STATUS AGE i-2ze0tfg75y5plzvnd29h Ready,SchedulingDisabled 2d i-2ze0woc5l1230xs5zxry Ready 2d i-2ze14a3m7riw0l18oemg Ready 2d i-2ze14a3m7riw0l18oemh Ready 2d i-2ze1nwnt9tc3wg83rsru Ready 2d 获取更详细的信息可以使用如下命令\n# kubectl get nodes -o wide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME cn-shanghai.i-uf6143y5dc78k Ready master 1y v1.11.5 172.18.88.44 \u0026lt;none\u0026gt; CentOS Linux 7 (Core) 3.10.0-693.2.2.el7.x86_64 docker://17.6.2 cn-shanghai.i-uf61jtxho26 Ready \u0026lt;none\u0026gt; 247d v1.11.5 172.18.89.45 \u0026lt;none\u0026gt; CentOS Linux 7 (Core) 3.10.0-693.2.2.el7.x86_64 docker://17.6.2 更详细的信息\n# kubectl describe nodes cn-shanghai.i-uf6143y5dc\n···信息太长这里就不展示了\npod pod是kubernetes非常重要的概念，他是运行应用的载体。有人说，pod是容器吗？等同吗？pod不是容器，pod更像是容器的封装体，如果把容器比喻为一个个的木箱子，那么pod就像是一个集装箱，一个集装箱可以装一个或多个木箱子，并且有挂钩这些方便吊装的装置。所以说pod是容器的封装，解决的是容器编排问题。\n获取pod，不指定名称空间\n# kubectl get pods 获取pod，指定名称空间，名称空间就是www\n# kubectl get pods -n www\nNAME READY STATUS RESTARTS AGE nginx-646b46d648-hbwg2 1/1 Running 0 101s 获取pod运行于哪个节点\n# kubectl get pods -n www -o wide\nNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES nginx-646b46d648-hbwg2 1/1 Running 0 2m23s 172.17.0.11 minikube \u0026lt;none\u0026gt; 获取pod中的日志\n# kubectl logs 646b46d648-hbwg2\n交互方式进入pod的内部\n# kubectl exec -it nginx-646b46d648-hbwg2 /bin/bash\n对pod执行一个命令\n# kubectl exec nginx-t213217u -- ls -l\n这里的双横线（\u0026ndash;）区分的是本地终端命令和容器中执行的命令，当中执行的命令只有一个单词时，可以忽略。\nNamespace namespace， 名称空间，是一个虚拟的空间，主要是用来构建一个虚拟的资源成，将资源池划分成多个虚拟的区域，互不干扰。不通资源池的资源可以重名，但是名称空间本身不可以重名，相同的名称空间内的资源也不可以重名。\n获取名称空间\n# kubectl get ns NAME STATUS AGE default Active 27h kube-node-lease Active 27h kube-public Active 27h kube-system Active 27h tutorial Active 7s ","date":"2020-03-03T23:03:27+08:00","permalink":"http://localhost:1313/p/kubernetes%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B51/","title":"Kubernetes基本概念(1)"},{"content":"python装饰器 python函数的几个核心概念 1，函数可以赋值给变量\ndef func(message): print(\u0026#34;got\u0026#34;) send = func send(\u0026#34;hello\u0026#34;) 2，函数可以当做参数传递给另一个函数\ndef get(message): return message def root(func, message): print(func(message)) root(get, \u0026#34;message\u0026#34;) 3,函数里定义函数，返回函数\ndef func(message): def get(message): print(message) return get(message) 4，看一个装饰器的例子\ndef my(func): def wa(): print(\u0026#34;1111\u0026#34;) func() return wa def geet(): print(\u0026#39;ello\u0026#39;) geet = my(geet) geet() 变量指向内部函数wa，内部函数wa调用geet函数本身，所以装饰器的根本含义就是把要执行的函数包裹在其中，并且附加了一些功能 更优雅的表示如下：\ndef my(func): def wa(): print(\u0026#34;1111\u0026#34;) func() return wa @my def geet(): print(\u0026#39;ello\u0026#39;) geet() 这里的@是一个语法糖，作用相当于geet=my（geet），只不过更加简洁，大大提高程序的可读性。\n带参数的装饰器 通常情况下我们会把*args和 **kwargs作为装饰器内部函数的参数，表示接受任意数量和类型的参数\n","date":"2020-03-03T23:03:27+08:00","permalink":"http://localhost:1313/p/python%E8%A3%85%E9%A5%B0%E5%99%A8/","title":"Python装饰器"}]